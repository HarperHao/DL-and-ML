{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWOZV94kYsbM"
   },
   "source": [
    "在实际应用中许多数据都以图(graph)的形式存在，比如，互联网、社交网络都可以看作是一个图。图数据上的机器学习具有理论与应用上的重要意义。pageRank算法是图的链接分析 (link analysis)的代表性算法，属于图数据上的无监督学习方法。  \n",
    "\n",
    "pageRank算法最初作为互联网网页重要度的计算方法，1996年由page和Brin提出，并用于谷歌搜索引擎的网页排序。事实上，pageRank可以定义在任意有向图上，后来被应用到社会影响力分析、文本摘要等多个问题。  \n",
    "\n",
    "pageRank算法的基本想法是在有向图上定义一个随机游走模型，即一阶马尔可夫链，描述随机游走者沿着有向图随机访问各个结点的行为。在一定条件下，极限情况访问每个结点的概率收敛到平稳分布， 这时各个结点的平稳概率值就是其 pageRank值，表示结点的重要度。 pageRank是递归定义的，pageRank的计算可以通过迭代算法进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T07:04:34.233229Z",
     "start_time": "2020-04-29T07:04:34.040701Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fAN4q0cqYn-f"
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/diogojc/1338222/84d767a68da711a154778fb1d00e772d65322187\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "def pageRank(G, s = .85, maxerr = .0001):\n",
    "    \"\"\"\n",
    "    Computes the pagerank for each of the n states\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: matrix representing state transitions\n",
    "       Gij is a binary value representing a transition from state i to j.\n",
    "    s: probability of following a transition. 1-s probability of teleporting\n",
    "       to another state.\n",
    "    maxerr: if the sum of pageranks between iterations is bellow this we will\n",
    "            have converged.\n",
    "    \"\"\"\n",
    "    n = G.shape[0]\n",
    "\n",
    "    # transform G into markov matrix A\n",
    "    A = csc_matrix(G,dtype=np.float)\n",
    "    rsums = np.array(A.sum(1))[:,0]\n",
    "    ri, ci = A.nonzero()\n",
    "    A.data /= rsums[ri]\n",
    "\n",
    "    # bool array of sink states\n",
    "    sink = rsums==0\n",
    "\n",
    "    # Compute pagerank r until we converge\n",
    "    ro, r = np.zeros(n), np.ones(n)\n",
    "    while np.sum(np.abs(r-ro)) > maxerr:\n",
    "        ro = r.copy()\n",
    "        # calculate each pagerank at a time\n",
    "        for i in range(0,n):\n",
    "            # inlinks of state i\n",
    "            Ai = np.array(A[:,i].todense())[:,0]\n",
    "            # account for sink states\n",
    "            Di = sink / float(n)\n",
    "            # account for teleportation to state i\n",
    "            Ei = np.ones(n) / float(n)\n",
    "\n",
    "            r[i] = ro.dot( Ai*s + Di*s + Ei*(1-s) )\n",
    "\n",
    "    # return normalized pagerank\n",
    "    return r/float(sum(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T07:04:36.264096Z",
     "start_time": "2020-04-29T07:04:35.514243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Ds-wQEFFZ1F7",
    "outputId": "b2860902-8712-4583-ab47-bec602c6791b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12727557 0.03616954 0.12221594 0.22608452 0.28934412 0.03616954\n",
      " 0.16274076]\n"
     ]
    }
   ],
   "source": [
    "# Example extracted from 'Introduction to Information Retrieval'\n",
    "G = np.array([[0,0,1,0,0,0,0],\n",
    "              [0,1,1,0,0,0,0],\n",
    "              [1,0,1,1,0,0,0],\n",
    "              [0,0,0,1,1,0,0],\n",
    "              [0,0,0,0,0,0,1],\n",
    "              [0,0,0,0,0,1,1],\n",
    "              [0,0,0,1,1,0,1]])\n",
    "print(pageRank(G,s=.86))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Box-Muller 变换] 如果随机变量 $U_1, U_2$ 独立且$U_1, U_2 \\sim Uniform[0,1]$，\n",
    "\n",
    "\\begin{align*} Z_0 & = \\sqrt{-2\\ln U_1} cos(2\\pi U_2) \\\\ Z_1 & = \\sqrt{-2\\ln U_1} sin(2\\pi U_2) \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过我们并不是总是这么幸运的，当$p(x)$的形式很复杂，或者 $p(\\mathbf{x})$ 是个高维的分布的时候，样本的生成就可能很困难了。 譬如有如下的情况\n",
    "\n",
    "$\\displaystyle p(x) = \\frac{\\tilde{p}(x)}{\\int \\tilde{p}(x) dx}$, 而 $\\tilde{p}(x)$ 我们是可以计算的，但是底下的积分式无法显式计算。\n",
    "$p(x,y)$ 是一个二维的分布函数，这个函数本身计算很困难，但是条件分布 $p(x|y),p(y|x)$的计算相对简单; 如果 $p(\\mathbf{x})$ 是高维的，这种情形就更加明显。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "马氏链的数学定义很简单\n",
    "\n",
    "$$ P(X_{t+1}=x|X_t, X_{t-1}, \\cdots) =P(X_{t+1}=x|X_t) $$\n",
    "\n",
    "也就是状态转移的概率只依赖于前一个状态。\n",
    "\n",
    "我们先来看马氏链的一个具体的例子。社会学家经常把人按其经济状况分成 3 类：下层 (lower-class)、中层 (middle-class)、上层 (upper-class)，我们用 1、2、3 分别代表这三个阶层。社会学家们发现决定一个人的收入阶层的最重要的因素就是其父母的收入阶层。如果一个人的收入属于下层类别，那么他的孩子属于下层收入的概率是 0.65，属于中层收入的概率是 0.28，属于上层收入的概率是 0.07。事实上，从父代到子代，收入阶层的变化的转移概率如下\n",
    "\n",
    "table-1\n",
    "\n",
    "markov-transition\n",
    "\n",
    "使用矩阵的表示方式，转移概率矩阵记为\n",
    "\n",
    "$$P = \\begin{bmatrix} 0.65 & 0.28 & 0.07 \\\\ 0.15 & 0.67 & 0.18 \\\\ 0.12 & 0.36 & 0.52 \\\\ \\end{bmatrix} $$\n",
    "\n",
    "假设当前这一代人处在下层、中层、上层的人的比例是概率分布向量 $\\pi_0=[\\pi_0(1), \\pi_0(2), \\pi_0(3)]$，那么他们的子女的分布比例将是 $\\pi_1=\\pi_0P$, 他们的孙子代的分布比例将是 $\\pi_2 = \\pi_1P=\\pi_0P^2$, ……, 第$n$代子孙的收入分布比例将是 $\\pi_n = \\pi_{n-1}P = \\pi_0P^n$。\n",
    "\n",
    "假设初始概率分布为$\\pi_0 = [0.21,0.68,0.11] $，则我们可以计算前$n$代人的分布状况如下\n",
    "\n",
    "table-2\n",
    "\n",
    "我们发现从第 7 代人开始，这个分布就稳定不变了，这个是偶然的吗？我们换一个初始概率分布$\\pi_0 = [0.75,0.15,0.1]$ 试试看，继续计算前$n$代人的分布状况如下\n",
    "\n",
    "table-3\n",
    "\n",
    "我们发现，到第 9 代人的时候, 分布又收敛了。最为奇特的是，两次给定不同的初始概率分布，最终都收敛到概率分布 $\\pi=[0.286, 0.489, 0.225]$，也就是说收敛的行为和初始概率分布 $\\pi_0$ 无关。这说明这个收敛行为主要是由概率转移矩阵 $P$ 决定的。我们计算一下 $P^n$\n",
    "\n",
    "$$ P^{20} = P^{21} = \\cdots = P^{100} = \\cdots = \\begin{bmatrix} 0.286 & 0.489 & 0.225 \\\\ 0.286 & 0.489 & 0.225 \\\\ 0.286 & 0.489 & 0.225 \\\\ \\end{bmatrix} $$\n",
    "\n",
    "我们发现，当 $n$ 足够大的时候，这个$P^n$矩阵的每一行都是稳定地收敛到$\\pi=[0.286, 0.489, 0.225]$ 这个概率分布。自然的，这个收敛现象并非是我们这个马氏链独有的，而是绝大多数马氏链的共同行为，关于马氏链的收敛我们有如下漂亮的定理：\n",
    "\n",
    "马氏链定理： 如果一个非周期马氏链具有转移概率矩阵$P$, 且它的任何两个状态是连通的，那么 $\\displaystyle \\lim_{n\\rightarrow\\infty}P_{ij}^n$ 存在且与$i$无关，记 $\\displaystyle \\lim_{n\\rightarrow\\infty}P_{ij}^n = \\pi(j)$， 我们有\n",
    "\n",
    "$$ \\displaystyle \\lim_{n \\rightarrow \\infty} P^n =\\begin{bmatrix} \\pi(1) & \\pi(2) & \\cdots & \\pi(j) & \\cdots \\\\ \\pi(1) & \\pi(2) & \\cdots & \\pi(j) & \\cdots \\\\ \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\ \\pi(1) & \\pi(2) & \\cdots & \\pi(j) & \\cdots \\\\ \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\ \\end{bmatrix} $$\n",
    "\n",
    "$ \\displaystyle \\pi(j) = \\sum_{i=0}^{\\infty}\\pi(i)P_{ij} $\n",
    "\n",
    "$\\pi$ 是方程 $\\pi P = \\pi$ 的唯一非负解\n",
    "\n",
    "其中,\n",
    "\n",
    "$$ \\pi = [\\pi(1), \\pi(2), \\cdots, \\pi(j),\\cdots ], \\quad \\sum_{i=0}^{\\infty} \\pi_i = 1 $$\n",
    "\n",
    "$\\pi$称为马氏链的平稳分布。\n",
    "\n",
    "这个马氏链的收敛定理非常重要，所有的 MCMC(Markov Chain Monte Carlo) 方法都是以这个定理作为理论基础的。定理的证明相对复杂，一般的随机过程课本中也不给证明，所以我们就不用纠结它的证明了，直接用这个定理的结论就好了。我们对这个定理的内容做一些解释说明：\n",
    "\n",
    "该定理中马氏链的状态不要求有限，可以是有无穷多个的；\n",
    "定理中的 “非周期” 这个概念我们不打算解释了，因为我们遇到的绝大多数马氏链都是非周期的；\n",
    "两个状态$i,j$是连通并非指$i$ 可以直接一步转移到$j$($P_{ij} > 0$)，而是指 $i$ 可以通过有限的$n$步转移到达$j$($P_{ij}^n > 0$)。马氏链的任何两个状态是连通的含义是指存在一个$n$，使得矩阵$P^n$ 中的任何一个元素的数值都大于零。\n",
    "我们用 $X_i$ 表示在马氏链上跳转第$i$步后所处的状态，如果$\\displaystyle \\lim_{n\\rightarrow\\infty}P_{ij}^n = \\pi(j)$存在，很容易证明以上定理的第二个结论。由于\n",
    "\\begin{align*} P(X_{n+1}=j) & = \\sum_{i=0}^\\infty P(X_n=i) P(X_{n+1}=j|X_n=i) \\\\ & = \\sum_{i=0}^\\infty P(X_n=i) P_{ij} \\end{align*}\n",
    "\n",
    "上式两边取极限就得到 $ \\displaystyle \\pi(j) = \\sum_{i=0}^{\\infty}\\pi(i)P_{ij}$\n",
    "\n",
    "从初始概率分布$\\pi_0$出发，我们在马氏链上做状态转移，记$X_i$的概率分布为$\\pi_i$，则有\n",
    "\n",
    "\\begin{align*} X_0 & \\sim \\pi_0(x)\\\\ X_i & \\sim \\pi_i(x), \\quad\\quad \\pi_i(x) = \\pi_{i-1}(x)P = \\pi_0(x)P^n \\end{align*}\n",
    "\n",
    "由马氏链收敛的定理, 概率分布$\\pi_i(x)$将收敛到平稳分布 $\\pi(x)$。假设到第$n$步的时候马氏链收敛，则有\n",
    "\n",
    "\\begin{align*} X_0 & \\sim \\pi_0(x) \\\\ X_1 & \\sim \\pi_1(x) \\\\ & \\cdots \\\\ X_n & \\sim \\pi_n(x)=\\pi(x) \\\\ X_{n+1} & \\sim \\pi(x) \\\\ X_{n+2}& \\sim \\pi(x) \\\\ & \\cdots \\end{align*}\n",
    "\n",
    "所以 $X_n,X_{n+1},X_{n+2},\\cdots \\sim \\pi(x)$ 都是同分布的随机变量，当然他们并不独立。如果我们从一个具体的初始状态 $x_0$ 开始, 沿着马氏链按照概率转移矩阵做跳转，那么我们得到一个转移序列 $x_0, x_1, x_2, \\cdots x_n, x_{n+1}\\cdots,$ 由于马氏链的收敛行为， $x_n, x_{n+1},\\cdots$ 都将是平稳分布 $\\pi(x)$ 的样本。\n",
    "\n",
    "3.3 Markov Chain Monte Carlo\n",
    "对于给定的概率分布$p(x)$, 我们希望能有便捷的方式生成它对应的样本。由于马氏链能收敛到平稳分布， 于是一个很的漂亮想法是：如果我们能构造一个转移矩阵为 $P$ 的马氏链，使得该马氏链的平稳分布恰好是$p(x)$， 那么我们从任何一个初始状态$x_0$出发沿着马氏链转移, 得到一个转移序列$x_0, x_1, x_2, \\cdots x_n, x_{n+1}\\cdots,$， 如果马氏链在第$n$步已经收敛了，于是我们就得到了$\\pi(x)$的样本$x_n, x_{n+1}\\cdots$。\n",
    "\n",
    "这个绝妙的想法在 1953 年被 Metropolis 想到了，为了研究粒子系统的平稳性质， Metropolis 考虑了物理学中常见的波尔兹曼分布的采样问题，首次提出了基于马氏链的蒙特卡罗方法，即 Metropolis 算法，并在最早的计算机上编程实现。Metropolis 算法是首个普适的采样方法，并启发了一系列 MCMC 方法，所以人们把它视为随机模拟技术腾飞的起点。 Metropolis 的这篇论文被收录在《统计学中的重大突破》中， Metropolis 算法也被遴选为二十世纪的十个最重要的算法之一。\n",
    "\n",
    "我们接下来介绍的 MCMC 算法是 Metropolis 算法的一个改进变种，即常用的 Metropolis-Hastings 算法。由上一节的例子和定理我们看到了，马氏链的收敛性质主要由转移矩阵$P$决定, 所以基于马氏链做采样的关键问题是如何构造转移矩阵$P$, 使得平稳分布恰好是我们要的分布$p(x)$。如何能做到这一点呢？我们主要使用如下的定理。\n",
    "\n",
    "定理：[细致平稳条件] 如果非周期马氏链的转移矩阵$P$和分布$\\pi(x)$满足\n",
    "\n",
    "\\begin{equation} \\pi(i)P_{ij} = \\pi(j)P_{ji} \\quad\\quad \\text{for all} \\quad i,j \\end{equation}\n",
    "\n",
    "则$\\pi(x)$是马氏链的平稳分布，上式被称为细致平稳条件 (detailed balance condition)。\n",
    "\n",
    "其实这个定理是显而易见的，因为细致平稳条件的物理含义就是对于任何两个状态$i,j$，从 $i$ 转移出去到$j$而丢失的概率质量，恰好会被从$j$转移回$i$的概率质量补充回来，所以状态 $i$ 上的概率质量$\\pi(i)$是稳定的，从而$\\pi(x)$是马氏链的平稳分布。数学上的证明也很简单，由细致平稳条件可得\n",
    "\n",
    "\\begin{align*} & \\sum_{i=1}^\\infty \\pi(i)P_{ij} = \\sum_{i=1}^\\infty \\pi(j)P_{ji} = \\pi(j) \\sum_{i=1}^\\infty P_{ji} = \\pi(j) \\\\ & \\Rightarrow \\pi P = \\pi \\end{align*}\n",
    "\n",
    "由于$\\pi$是方程$\\pi P = \\pi$的解，所以$\\pi$是平稳分布。\n",
    "\n",
    "假设我们已经有一个转移矩阵为$Q$马氏链 ($q(i,j)$表示从状态$i$转移到状态$j$的概率，也可以写为$q(j|i)$或者$q(i\\rightarrow j)$), 显然，通常情况下$$ p(i) q(i,j) \\neq p(j) q(j,i)$$也就是细致平稳条件不成立，所以$p(x)$不太可能是这个马氏链的平稳分布。我们可否对马氏链做一个改造，使得细致平稳条件成立呢？譬如，我们引入一个 $\\alpha(i,j)$，我们希望\n",
    "\n",
    "\\begin{equation} \\label{choose-alpha} p(i) q(i,j)\\alpha(i,j) = p(j) q(j,i)\\alpha(j,i)  \\quad (*) \\end{equation}\n",
    "\n",
    "取什么样的 $\\alpha(i,j)$ 以上等式能成立呢？最简单的，按照对称性，我们可以取\n",
    "\n",
    "$$ \\alpha(i,j)= p(j) q(j,i)， \\quad \\alpha(j,i) = p(i) q(i,j)$$\n",
    "\n",
    "于是 (*) 式就成立了。所以有\n",
    "\n",
    "\\begin{equation} \\label{detailed-balance} p(i) \\underbrace{q(i,j)\\alpha(i,j)}_{Q'(i,j)} = p(j) \\underbrace{q(j,i)\\alpha(j,i)}_{Q'(j,i)} \\quad (**) \\end{equation}\n",
    "\n",
    "于是我们把原来具有转移矩阵 $Q$ 的一个很普通的马氏链，改造为了具有转移矩阵$Q’$的马氏链，而 $Q’$恰好满足细致平稳条件，由此马氏链$Q’$的平稳分布就是$p(x)$！\n",
    "\n",
    "在改造 $Q$ 的过程中引入的$\\alpha(i,j)$称为接受率，物理意义可以理解为在原来的马氏链上，从状态 $i$ 以$q(i,j)$ 的概率转跳转到状态$j$ 的时候，我们以$\\alpha(i,j)$的概率接受这个转移，于是得到新的马氏链$Q’$的转移概率为$q(i,j)\\alpha(i,j)$。\n",
    "\n",
    "mcmc-transition\n",
    "\n",
    "马氏链转移和接受概率\n",
    "\n",
    "假设我们已经有一个转移矩阵 Q(对应元素为$q(i,j)$), 把以上的过程整理一下，我们就得到了如下的用于采样概率分布$p(x)$的算法。\n",
    "\n",
    "mcmc-algo-1\n",
    "\n",
    "上述过程中$p(x),q(x|y)$说的都是离散的情形，事实上即便这两个分布是连续的，以上算法仍然是有效，于是就得到更一般的连续概率分布$p(x)$的采样算法，而$q(x|y)$就是任意一个连续二元概率分布对应的条件分布。\n",
    "\n",
    "以上的 MCMC 采样算法已经能很漂亮的工作了，不过它有一个小的问题：马氏链$Q$在转移的过程中的接受率$\\alpha(i,j)$可能偏小，这样采样过程中马氏链容易原地踏步，拒绝大量的跳转，这使得马氏链遍历所有的状态空间要花费太长的时间，收敛到平稳分布$p(x)$的速度太慢。有没有办法提升一些接受率呢?\n",
    "\n",
    "假设$\\alpha(i,j)=0.1, \\alpha(j,i)=0.2$, 此时满足细致平稳条件，于是\n",
    "\n",
    "$$ p(i)q(i,j)\\times 0.1 = p(j)q(j,i) \\times 0.2 $$\n",
    "\n",
    "上式两边扩大 5 倍，我们改写为\n",
    "\n",
    "$$ p(i)q(i,j) \\times 0.5 = p(j)q(j,i) \\times 1 $$\n",
    "\n",
    "看，我们提高了接受率，而细致平稳条件并没有打破！这启发我们可以把细致平稳条件 (**) 式中的$\\alpha(i,j),\\alpha(j,i)$ 同比例放大，使得两数中最大的一个放大到 1，这样我们就提高了采样中的跳转接受率。所以我们可以取\n",
    "\n",
    "$$ \\alpha(i,j) = \\min\\left\\{\\frac{p(j)q(j,i)}{p(i)q(i,j)},1\\right\\} $$\n",
    "\n",
    "于是，经过对上述 MCMC 采样算法中接受率的微小改造，我们就得到了如下教科书中最常见的 Metropolis-Hastings 算法。\n",
    "\n",
    "mcmc-algo-2\n",
    "\n",
    "对于分布 $p(x)$, 我们构造转移矩阵 $Q’$ 使其满足细致平稳条件\n",
    "\n",
    "$$ p(x) Q'(x\\rightarrow y) = p(y) Q'(y\\rightarrow x) $$\n",
    "\n",
    "此处$x$并不要求是一维的，对于高维空间的 $p(\\mathbf{x})$，如果满足细致平稳条件\n",
    "\n",
    "$$ p(\\mathbf{x}) Q'(\\mathbf{x}\\rightarrow \\mathbf{y}) = p(\\mathbf{y}) Q'(\\mathbf{y}\\rightarrow \\mathbf{x}) $$\n",
    "\n",
    "那么以上的 Metropolis-Hastings 算法一样有效。\n",
    "\n",
    "3.4 Gibbs Sampling\n",
    "对于高维的情形，由于接受率$\\alpha$的存在 (通常 $\\alpha < 1$)，以上 Metropolis-Hastings 算法的效率不够高。能否找到一个转移矩阵 Q 使得接受率 $\\alpha=1$ 呢？我们先看看二维的情形，假设有一个概率分布 $p(x,y)$， 考察 $x$ 坐标相同的两个点$A(x_1,y_1), B(x_1,y_2)$，我们发现\n",
    "\n",
    "\\begin{align*} p(x_1,y_1)p(y_2|x_1) = p(x_1)p(y_1|x_1)p(y_2|x_1) \\\\ p(x_1,y_2)p(y_1|x_1) = p(x_1)p(y_2|x_1)p(y_1|x_1) \\end{align*}\n",
    "\n",
    "所以得到\n",
    "\n",
    "\\begin{equation} \\label{gibbs-detailed-balance} p(x_1,y_1)p(y_2|x_1) = p(x_1,y_2)p(y_1|x_1)  \\quad (***) \\end{equation}\n",
    "\n",
    "即\n",
    "\n",
    "$$ p(A)p(y_2|x_1) = p(B)p(y_1|x_1) $$\n",
    "\n",
    "基于以上等式，我们发现，在 $x=x_1$ 这条平行于 $y$轴的直线上，如果使用条件分布 $p(y|x_1)$做为任何两个点之间的转移概率，那么任何两个点之间的转移满足细致平稳条件。同样的，如果我们在$y=y_1$ 这条直线上任意取两个点 $A(x_1,y_1), C(x_2,y_1)$，也有如下等式\n",
    "\n",
    "$$ p(A)p(x_2|y_1) = p(C)p(x_1|y_1). $$\n",
    "\n",
    "gibbs-transition\n",
    "\n",
    "平面上马氏链转移矩阵的构造\n",
    "\n",
    "于是我们可以如下构造平面上任意两点之间的转移概率矩阵 Q\n",
    "\n",
    "\\begin{align*} Q(A\\rightarrow B) & = p(y_B|x_1) & \\text{如果} \\quad x_A=x_B=x_1 & \\\\ Q(A\\rightarrow C) & = p(x_C|y_1) & \\text{如果} \\quad y_A=y_C=y_1 & \\\\ Q(A\\rightarrow D) & = 0 & \\text{其它} & \\end{align*}\n",
    "\n",
    "有了如上的转移矩阵 Q，我们很容易验证对平面上任意两点 $X,Y$， 满足细致平稳条件\n",
    "\n",
    "$$ p(X)Q(X\\rightarrow Y) = p(Y) Q(Y\\rightarrow X) $$\n",
    "\n",
    "于是这个二维空间上的马氏链将收敛到平稳分布 $p(x,y)$。而这个算法就称为 Gibbs Sampling 算法，是 Stuart Geman 和 Donald Geman 这两兄弟于 1984 年提出来的，之所以叫做 Gibbs Sampling 是因为他们研究了 Gibbs random field，这个算法在现代贝叶斯分析中占据重要位置。\n",
    "\n",
    "gibbs-algo-1\n",
    "\n",
    "two-stage-gibbs\n",
    "\n",
    "Gibbs Sampling 算法中的马氏链转移\n",
    "\n",
    "以上采样过程中，如图所示，马氏链的转移只是轮换的沿着坐标轴$x$轴和$y$轴做转移，于是得到样本$(x_0,y_0),(x_0,y_1),(x_1,y_1), (x_1,y_2),(x_2,y_2), \\cdots $马氏链收敛后，最终得到的样本就是 $p(x,y)$的样本，而收敛之前的阶段称为 burn-in period。额外说明一下，我们看到教科书上的 Gibbs Sampling 算法大都是坐标轴轮换采样的，但是这其实是不强制要求的。最一般的情形可以是，在$t$时刻，可以在$x$轴和$y$轴之间随机的选一个坐标轴，然后按条件概率做转移，马氏链也是一样收敛的。轮换两个坐标轴只是一种方便的形式。\n",
    "\n",
    "以上的过程我们很容易推广到高维的情形，对于 (***) 式，如果$x_1$变为多维情形$\\mathbf{x_1}$，可以看出推导过程不变，所以细致平稳条件同样是成立的\n",
    "\n",
    "\\begin{equation} \\label{gibbs-detailed-balance-n-dimen} p(\\mathbf{x_1},y_1)p(y_2|\\mathbf{x_1}) = p(\\mathbf{x_1},y_2)p(y_1|\\mathbf{x_1}) \\end{equation}\n",
    "\n",
    "此时转移矩阵 Q 由条件分布$p(y|\\mathbf{x_1})$定义。上式只是说明了一根坐标轴的情形，和二维情形类似，很容易验证对所有坐标轴都有类似的结论。所以 $n$ 维空间中对于概率分布 $p(x_1,x_2,\\cdots, x_n)$可以如下定义转移矩阵\n",
    "\n",
    "1. 如果当前状态为$(x_1,x_2,\\cdots,x_n)$，马氏链转移的过程中，只能沿着坐标轴做转移。沿着$x_i$这根坐标轴做转移的时候，转移概率由条件概率$p(x_i|x_1, \\cdots, x_{i-1}, x_{i+1}, \\cdots, x_n)$定义； 2.  其它无法沿着单根坐标轴进行的跳转，转移概率都设置为 0。\n",
    "\n",
    "于是我们可以把 Gibbs Smapling 算法从采样二维的$p(x,y)$推广到采样$n$维的$p(x_1,x_2,\\cdots, x_n)$\n",
    "\n",
    "gibbs-algo-2\n",
    "\n",
    "以上算法收敛后，得到的就是概率分布$p(x_1,x_2,\\cdots,x_n)$的样本，当然这些样本并不独立，但是我们此处要求的是采样得到的样本符合给定的概率分布，并不要求独立。同样的，在以上算法中，坐标轴轮换采样不是必须的，可以在坐标轴轮换中引入随机性，这时候转移矩阵$Q$中任何两个点的转移概率中就会包含坐标轴选择的概率，而在通常的 Gibbs Sampling 算法中，坐标轴轮换是一个确定性的过程，也就是在给定时刻$t$，在一根固定的坐标轴上转移的概率是 1。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PageRank.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
